{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292319de",
   "metadata": {},
   "source": [
    "# Training a sentiment classifier\n",
    "\n",
    "Task: Create a function that takes a text string as input and outputs itâ€™s sentiment (positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, DataCollatorWithPadding, pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ce9c7",
   "metadata": {},
   "source": [
    "# Training data\n",
    "\n",
    "For training a sentiment classifier, we need a dataset that contains text documents and sentiment labels (positive or negative).\n",
    "\n",
    "Here we are going to use movie reviews from the Internet movie database (IMDB). Each movie review consists of a textual review and a rating value (originally 1 to 10 stars, but has been converted to positive/negative here). \n",
    "\n",
    "There's a nice helper function that takes care of loading the data from Internet.\n",
    "\n",
    "We don't need the whole dataset. Let's take a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33067b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")\n",
    "\n",
    "imdb_small_train = imdb['train'].shuffle(seed=42).select(range(1000))\n",
    "imdb_small_test = imdb['test'].shuffle(seed=42).select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab07eaa",
   "metadata": {},
   "source": [
    "How does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_small_train.select(range(10)).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524ab2e",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "We don't train the sentiment classifier model from scratch. Instead, we reuse a [pre-trained language model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) that has been trained on very large text collections to predict the similarity of sentences.\n",
    "\n",
    "We only need to fine-tune it for the sentiment prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf1c4bd",
   "metadata": {},
   "source": [
    "A minor technical detail: The expected input for the pre-trained model is not the raw text but a list of token indexes. We need to load and apply the tokenizer matching the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1116de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('I wonder how does this sentence looks like tokenized?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cb32d",
   "metadata": {},
   "source": [
    "Next, preprocess the IMDB dataset by applying the tokenizer on each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "tokenized_imdb_train = imdb_small_train.map(preprocess_function, batched=True)\n",
    "tokenized_imdb_test = imdb_small_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c516cf2",
   "metadata": {},
   "source": [
    "We want to fine-tune the pre-trained model to output POSITIVE or NEGATIVE. Here we configure a two-class classifier on top of the pre-trained language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                    num_labels=2,\n",
    "                                    id2label={0: 'NEGATIVE', 1: 'POSITIVE'},\n",
    "                                    label2id={'NEGATIVE': 0, 'POSITIVE': 1})\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752d7ca",
   "metadata": {},
   "source": [
    "Training the sentiment classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none',\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb_train,\n",
    "    eval_dataset=tokenized_imdb_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d60ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('models/checkpoint-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6d69f",
   "metadata": {},
   "source": [
    "## The sentiment function\n",
    "\n",
    "We have just trained a model that predicts if a text has positive or negative sentiment.\n",
    "\n",
    "Let's package the tokenizer and the trained model into a simple function called `sentiment` that takes a text string as input and outputs the predicted sentiment (and also a score that indicates how certain the prediction is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment('The movie was awesome!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5576e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment('Acting was bad and the plot was horrible')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0004d2",
   "metadata": {},
   "source": [
    "## A simple UI for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99338a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_wrapper(text):\n",
    "    return str(sentiment(text)[0])\n",
    "\n",
    "app = gr.Interface(fn=sentiment_wrapper, inputs=\"text\", outputs=\"text\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b96f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
